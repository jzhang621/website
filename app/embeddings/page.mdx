import RemoveWord from '@/components/embeddings/RemoveWord';
import CustomImage from '@/components/Image';
import Image from 'next/image';
import { pg_remove_words_results } from '@/data/words/pg_remove_words_results';

import Wattenberger from '../../public/images/wattenberger.png';
import ChatGPT from '../../public/images/chat-gpt-transform.png';
import Brighten from '../../public/images/brighten.png';
import Gray from '../../public/images/gray.png';
import GrayScale from '../../public/images/gray-scale.png';
import BrightenSingle from '../../public/images/brighten-single.png';
import GraySingle from '../../public/images/gray-single.png';
import Prism from '../../public/images/prism-toolbar.png';
import Red from '../../public/images/red.png';

import ColorSwatch from '@/components/rgb/ColorSwatch';
import { generateRGBGradient } from '@/data/utils';

export const metadata = {
    published: true,
    title: "Embeddings Unlock New Functionality",
    description: "We can now write functions that allow us to work with text in new ways.",
    date: "2024-12-03",
};

export const grays = generateRGBGradient([ 90, 90, 90], [180, 180, 180], 3);

# Embeddings Unlock New Functionality

In 2018, I tried to visualize what good writing looked like. This meant defining good writing computationally: could I write functions that took in a piece of writing as input, and returned some dimension of “good” writing as output? 

Back then, the functions I was capable of writing weren’t very interesting. They dealt mostly with counts - given a sentence, return the number of words in that sentence. I didn’t find them to be particularly useful, and so I stopped my attempt. 

In hindsight, I needed a better way to represent text. I was working with strings - which are great for displaying text, but limited when it comes to extracting insights. 

*Embeddings* are that better representation. But before going into what embeddings are and what makes them better, let’s first establish what makes a representation “good” by looking at how computers represent colors.

### RGB Color Model

We intuitively understand colors when we see them, but how do we get a computer to represent them? Enter the RGB model.

Computers use 24-bit integers to describe colors, which means it is capable of displaying ~16.7 million unique colors. The RGB color model breaks those 24 bits into three separate 8-bit dimensions. Each dimension corresponds to an intensity of red (R), green (G), and blue (B) light known as *channels*, ranging from 0 to 255. 


Under the RGB color model, if we have a color, and we want to make it more red, we have an easy way of doing so in terms of its underlying representation - we increase the red channel while keeping the other channels constant. 

<div className="my-12">
<div className="flex justify-center">
```javascript
function moreRed(color: [number, number, number], amount: number) {
	const [r, g, b] = color;
	return [r + amount, g, b];
}
```
</div>
<figcaption className="mt-8 text-center text-sm text-gray-500">Note: this function should clamp all values between 0 and 255, but I’m excluding that for clarity of concept.</figcaption>
</div>

The ease with which we can express this transformation is what makes the RGB color model a “good” representation of color. Here are a couple of other transformations available to us:

### Brightness

To brighten* a color, we can increase the value of each channel by the same relative amount. 

<div className="flex justify-center my-12">
```javascript
// brightens the color by % `amount` (i.e. 10%)
function brighten(color: [number, number, number], amount: number) {
	const [r, g, b] = color;
	return [r * amount, g * amount, b * amount];
}
```
</div>

We can see the effects of this transformation when it is applied to a single color.

<div className="flex justify-center w-5/6 my-12 px-12 mx-auto">
  <Image src={BrightenSingle} alt="Brightening a single color"  />
</div>

We can more easily understand the effects of this transformation when it is applied to all pixels of an image. 

<div className="flex justify-center w-5/6 my-12 px-12 mx-auto">
  <Image src={Brighten} alt="Brightening an image"  />
</div>

### Grayness

In the RGB color model, colors that have equal intensity across all three channels (i.e. `r = g = b`) are perceived as gray. 

<div className="flex gap-8 justify-center my-8 py-4 rounded-sm">
{grays.map((color, index) => (
 <ColorSwatch rgb={color} key={index} />
))}
</div>

This means we can turn an input color "gray" by calculating the average of its three channels, and returning a new color where all channels have that average. 

<div className="flex justify-center my-12">
```javascript
function gray(color: [number, number, number]) {
	const [r, g, b] = color;
    const avg = (r + g + b) / 3;
	return [avg, avg, avg];
}
```
</div>

<div className="my-12 px-12 w-5/6 mx-auto">
  <Image src={GraySingle} alt="Graying a single color"  />
</div>

When applied to each pixel of an image:

<div className="flex justify-center w-5/6 my-12 px-12 mx-auto">
  <Image src={Gray} alt="Graying an image"  />
</div>

These functions should already be familiar to you - they’re the basis for Instagram Filters.

### Text Embeddings

So this is what we’re after: a good representation for text. One that makes it possible to define functions that take in text and achieve specific outcomes. One that makes it easier to work with text computationally. This brings us back to embeddings.

An *embedding* is a way of describing a piece of text (we’ll stick to sentences in this post) as a list of numbers. To create an embedding, you take a sentence and pass it through an embedding model. 

```python
model.encode(”This is a sentence I will generate an embedding for.”) → [1234, …, …, …]
```

You can take any sentence and run it through the embedding model - the output is always a list of length `N`. We refer to `N` as the *dimension* of the embedding. 


```python
model.encode(”My cat is being a trouble maker today.”) → [1234, …, …, …]
```

We can think of a single embedding as occupying a point in an N-dimensional space (an embedding is a *vector*). An embedding model thus maps all possible sentences to points in the same N-dimensional space. Here’s the most important part: they are mapped in such a way that **sentences with “similar meanings” sit closer together in that space** than sentences with different meanings.

```python
[need spatial visual here]

model.encode(”I want to generate an embedding for this sentence.”) → [1234, …, …, …]

model.encode(”I want to get an embedding for this sentence.”) → [1234, …, …, …]

model.encode(”My cat is being a trouble maker today.”) → [1234, …, …, …]
```

Once we have the embeddings of two sentences, we can measure the distance between them using *cosine similarity*. The embeddings of two sentences with similar meanings have cosine similarities closer to 1. Two sentences with dissimilar meanings [unrelated] have cosine similarities closer to 0. 

Cosine similarity is just a function - which takes us back to our primary goal of working with text computationally. Thanks to embeddings, we can write functions that measure how similar in meaning two sentences are.

### Computing With Embeddings

Here’s the start of a Paul Graham essay, [When to Do What You Love](https://www.paulgraham.com/when.html), with certain words highlighted with the help of embeddings:

<div className="m-8">
    <RemoveWord words={pg_remove_words_results} />
</div>

To create these highlights, I first generate embeddings for each sentence in the essay `(e1)` . I then looped through every word in each sentence, removed that word from the sentence, and generated an embedding for that shortened sentence `(e2)`.

I then calculate the cosine similarity between `e1` and `e2`, and use that value to drive the highlighting. Words, that when removed, produce larger differences in cosine similarity are highlighted darker. The result is a rough measure of how “important” a word is to the meaning of the sentence in which that word appears. 

This technique has its shortcomings. For one, long sentences tend to dilute the importance of any single word. Even so, I find it’s a helpful indicator of where to direct my attention. I like the idea of turning these highlights on after reading something for the first time, to see if there was anything I missed. 

But its not the virtues of any particular technique that excite me the most - it’s the fact that such techniques are even possible.


### Beyond Measurement

I use the fact that embeddings can measure “meaning” to demonstrate their usefulness, but they unlock much broader capabilities. 

Below, [Amelia Wattenberger](https://wattenberger.com/thoughts/yay-embeddings-math) demonstrates how embeddings can be used to measure sentences on a scale of “concrete” to “abstract”. (I <span className="italic">especially love</span> the view on the right-hand side which plots the entire essay along that scale).

<div className="my-24">
<div className="flex justify-center">
  <Image 
    src={Wattenberger} 
    alt="Description" 
    />
</div>
<figcaption className="mt-4 text-center text-sm text-gray-500">Credit: Amelia Wattenberger (https://wattenberger.com/thoughts/yay-embeddings-math)</figcaption>
</div>

But just as the RGB color model facilitates meaningful transforms of color, embeddings facilitate meaningful transformations of text. 



We can already do this with ChatGPT when we ask it to make a sentence more "concrete":

<div className="flex justify-center my-24">
<Image 
    src={ChatGPT} 
    alt="Transforming text with ChatGPT" 
    />
</div>


And this is because under the hood, the Large Language Models (LLMs) that power ChatGPT are just manipulating embeddings!

Right now, natural language (e.g. our prompts) is our interface to that manipulation. But more natural interfaces - ones that manipulate embeddings more precisely - like the text editing interface Linus Lee [imagines below](https://thesephist.com/posts/prism/) are possible:

<div className="my-24">
<div className="flex justify-center">
  <Image 
    src={Prism} 
    alt="Description" 
    height={500}
    />
</div>
<figcaption className="mt-4 text-center text-sm text-gray-500">Credit: Linus Lee (https://thesephist.com/posts/prism/)</figcaption>
</div>


But to really hone our sense of what’s possible, we have to understand how embedding models are created - which we’ll cover in the next post.


Stay tuned!